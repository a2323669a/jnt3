{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false,
          "name": "#%% read csv\n"
        }
      },
      "outputs": [],
      "source": "import pandas as pd\nimport numpy as np\ndf \u003d pd.read_csv(\"./data/salary/train.csv\")"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "source": "#change obj column to num\ndef to_num(df):\n    col_name \u003d df.columns.values\n    obj_list \u003d []\n    for name in col_name:\n        if df[name].dtype \u003d\u003d \u0027object\u0027:\n            obj_list.append(name)\n    obj_dict \u003d {}\n    for name in obj_list:#list of object column\n        keys \u003d list(dict(list(df.groupby(name))).keys())#various value of this column\n        obj_dict[name] \u003d keys\n        for i in range(len(keys)):\n            key \u003d keys[i]\n            df_col \u003d df[name]\n            df_col[df[name] \u003d\u003d key] \u003d i\n    return df,obj_dict\n# change num converted from obj to one-hot\ndef sperate_obj(df):\n    col_name \u003d df.columns.values\n    obj_list \u003d []\n    for name in col_name:\n        if df[name].dtype \u003d\u003d \u0027object\u0027:\n            obj_list.append(name)\n    obj_dict \u003d {}\n    for name in obj_list:#list of object column\n        keys \u003d list(dict(list(df.groupby(name))).keys())#various value of this column\n        \n        if len(keys) \u003c\u003d 2 :#value types no more than 2,change previous column only\n            obj_dict[name] \u003d keys\n            df_col \u003d df[name]\n            df_col[df[name] \u003d\u003d keys[0]] \u003d 0\n            df_col[df[name] !\u003d 0] \u003d 1\n        else:#need convert to on-hot,i.e.need add and drop columns\n            obj_dict[name] \u003d []\n            for key in keys:\n                #add new col\n                col_name \u003d name+\"_\"+key\n                df[col_name] \u003d 0\n                new_col \u003d df[col_name]\n                new_col[df[name] \u003d\u003d key] \u003d 1\n                obj_dict[name].append(col_name)\n                \n            #drop col\n            df.drop(name,axis \u003d 1,inplace\u003dTrue)\n        \n    return df,obj_dict",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% define fucntion\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "C:\\Users\\a2323\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "C:\\Users\\a2323\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\nC:\\Users\\a2323\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "df_convert,obj_dict \u003d sperate_obj(df)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% convert dataframe\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": "df_convert.to_csv(\"./result/salary/test.csv\")",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% save converted csv file\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "f \u003d open(\"./result/salary/test\",\u0027w\u0027)\nf.writelines(str(obj_dict))\nf.close()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% save dict to file\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": "df_label \u003d df_convert.loc[:,\u0027income\u0027]\ndf_train \u003d df_convert.drop(labels\u003d[\u0027income\u0027],axis\u003d1)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% select columns\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": "data_y \u003d df_label.values.reshape((1,-1)).astype(np.float) #(1,n)\n#must use astype(float),otherwise the dtype is object,will err in numpy operation\ndata_x \u003d df_train.values.astype(np.float) .T #(dim,n)\n#feature scaling\ndata_x \u003d (data_x - np.mean(data_x,axis\u003d1).reshape((-1,1)))/np.std(data_x,axis\u003d1).reshape((-1,1))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% prepare data for discrimitve model\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "C:\\Users\\a2323\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in log\nC:\\Users\\a2323\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in matmul\n"
          ],
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": [
            "loss:[[nan]],acc:0.7339762292312889\n",
            "loss:[[10899.15003055]],acc:0.8498203372132306\n",
            "loss:[[10483.02651867]],acc:0.8535671508860293\n",
            "loss:[[10387.29293272]],acc:0.8543042289855962\n",
            "loss:[[10347.24973267]],acc:0.8543349405730782\n",
            "loss:[[10326.75743632]],acc:0.8542428058106324\n",
            "loss:[[10314.98463587]],acc:0.853751420410921\n",
            "loss:[[10307.59344614]],acc:0.8537207088234391\n",
            "loss:[[10302.62986567]],acc:0.8535671508860293\n",
            "loss:[[10299.1489776]],acc:0.8535057277110654\n",
            "loss:[[10296.63961135]],acc:0.8534443045361014\n",
            "loss:[[10294.77608452]],acc:0.8535057277110654\n",
            "loss:[[10293.33958913]],acc:0.8534443045361014\n",
            "loss:[[10292.18901396]],acc:0.8534135929486195\n",
            "loss:[[10291.23588149]],acc:0.8533521697736556\n",
            "loss:[[10290.42450734]],acc:0.8533214581861737\n",
            "loss:[[10289.71911442]],acc:0.8533521697736556\n",
            "loss:[[10289.09608026]],acc:0.8532907465986916\n",
            "loss:[[10288.53932965]],acc:0.8533214581861737\n",
            "loss:[[10288.03756677]],acc:0.8533214581861737\n",
            "loss:[[10287.58258407]],acc:0.8532907465986916\n",
            "loss:[[10287.16821094]],acc:0.8533214581861737\n",
            "loss:[[10286.78964967]],acc:0.8533828813611376\n",
            "loss:[[10286.44304958]],acc:0.8534135929486195\n",
            "loss:[[10286.12523021]],acc:0.8534135929486195\n",
            "loss:[[10285.83349863]],acc:0.8533521697736556\n",
            "loss:[[10285.56552718]],acc:0.8532907465986916\n",
            "loss:[[10285.31927037]],acc:0.8532907465986916\n",
            "loss:[[10285.09290721]],acc:0.8533214581861737\n",
            "loss:[[10284.88480051]],acc:0.8532907465986916\n",
            "loss:[[10284.69346737]],acc:0.8533214581861737\n",
            "loss:[[10284.51755733]],acc:0.8533214581861737\n",
            "loss:[[10284.35583565]],acc:0.8533214581861737\n",
            "loss:[[10284.20717016]],acc:0.8532907465986916\n",
            "loss:[[10284.07052072]],acc:0.8532907465986916\n",
            "loss:[[10283.94493038]],acc:0.8533214581861737\n",
            "loss:[[10283.82951797]],acc:0.8532907465986916\n",
            "loss:[[10283.7234716]],acc:0.8532907465986916\n",
            "loss:[[10283.62604297]],acc:0.8532907465986916\n",
            "loss:[[10283.53654231]],acc:0.8532907465986916\n",
            "loss:[[10283.45433379]],acc:0.8532600350112097\n",
            "loss:[[10283.3788313]],acc:0.8532293234237278\n",
            "loss:[[10283.30949472]],acc:0.8532293234237278\n",
            "loss:[[10283.24582631]],acc:0.8531986118362458\n",
            "loss:[[10283.18736756]],acc:0.8531679002487639\n",
            "loss:[[10283.13369616]],acc:0.8531986118362458\n",
            "loss:[[10283.08442326]],acc:0.8531986118362458\n",
            "loss:[[10283.03919089]],acc:0.8531986118362458\n",
            "loss:[[10282.99766959]],acc:0.8531986118362458\n",
            "loss:[[10282.95955625]],acc:0.8531986118362458\n",
            "loss:[[10282.92457204]],acc:0.8531986118362458\n",
            "loss:[[10282.89246053]],acc:0.8531986118362458\n",
            "loss:[[10282.86298597]],acc:0.8531986118362458\n",
            "loss:[[10282.83593165]],acc:0.8531986118362458\n",
            "loss:[[10282.81109841]],acc:0.8531986118362458\n",
            "loss:[[10282.78830326]],acc:0.8531986118362458\n",
            "loss:[[10282.7673781]],acc:0.8532293234237278\n",
            "loss:[[10282.74816854]],acc:0.8532293234237278\n",
            "loss:[[10282.7305328]],acc:0.8532293234237278\n",
            "loss:[[10282.71434073]],acc:0.8532293234237278\n",
            "loss:[[10282.69947282]],acc:0.8532293234237278\n",
            "loss:[[10282.68581942]],acc:0.8532600350112097\n",
            "loss:[[10282.67327987]],acc:0.8532600350112097\n",
            "loss:[[10282.66176184]],acc:0.8532600350112097\n",
            "loss:[[10282.65118059]],acc:0.8532600350112097\n",
            "loss:[[10282.6414584]],acc:0.8532600350112097\n",
            "loss:[[10282.632524]],acc:0.8532600350112097\n",
            "loss:[[10282.62431199]],acc:0.8532600350112097\n",
            "loss:[[10282.61676242]],acc:0.8532600350112097\n",
            "loss:[[10282.60982031]],acc:0.8532600350112097\n",
            "loss:[[10282.60343526]],acc:0.8532907465986916\n",
            "loss:[[10282.59756104]],acc:0.8532907465986916\n",
            "loss:[[10282.59215529]],acc:0.8532907465986916\n",
            "loss:[[10282.58717918]],acc:0.8532907465986916\n",
            "loss:[[10282.58259709]],acc:0.8532907465986916\n",
            "loss:[[10282.5783764]],acc:0.8532907465986916\n",
            "loss:[[10282.57448719]],acc:0.8532907465986916\n",
            "loss:[[10282.57090207]],acc:0.8532907465986916\n",
            "loss:[[10282.56759589]],acc:0.8532907465986916\n",
            "loss:[[10282.56454565]],acc:0.8532907465986916\n",
            "loss:[[10282.56173024]],acc:0.8532907465986916\n",
            "loss:[[10282.55913031]],acc:0.8532907465986916\n",
            "loss:[[10282.55672816]],acc:0.8532907465986916\n",
            "loss:[[10282.55450754]],acc:0.8532907465986916\n",
            "loss:[[10282.55245356]],acc:0.8532907465986916\n",
            "loss:[[10282.55055259]],acc:0.8532907465986916\n",
            "loss:[[10282.54879212]],acc:0.8532907465986916\n",
            "loss:[[10282.54716071]],acc:0.8532907465986916\n",
            "loss:[[10282.54564785]],acc:0.8532907465986916\n",
            "loss:[[10282.54424391]],acc:0.8532907465986916\n",
            "loss:[[10282.54294009]],acc:0.8532907465986916\n",
            "loss:[[10282.54172828]],acc:0.8533214581861737\n",
            "loss:[[10282.54060109]],acc:0.8533214581861737\n",
            "loss:[[10282.53955171]],acc:0.8533214581861737\n",
            "loss:[[10282.53857392]],acc:0.8533214581861737\n",
            "loss:[[10282.53766201]],acc:0.8533214581861737\n",
            "loss:[[10282.53681074]],acc:0.8533214581861737\n",
            "loss:[[10282.53601531]],acc:0.8533214581861737\n",
            "loss:[[10282.53527131]],acc:0.8533214581861737\n",
            "loss:[[10282.53457471]],acc:0.8533214581861737\n",
            "loss:[[10282.5339218]],acc:0.8533214581861737\n",
            "loss:[[10282.53330919]],acc:0.8533214581861737\n",
            "loss:[[10282.53273374]],acc:0.8533214581861737\n",
            "loss:[[10282.53219261]],acc:0.8533214581861737\n",
            "loss:[[10282.53168316]],acc:0.8533214581861737\n",
            "loss:[[10282.53120298]],acc:0.8533214581861737\n",
            "loss:[[10282.53074986]],acc:0.8533214581861737\n",
            "loss:[[10282.53032177]],acc:0.8533214581861737\n",
            "loss:[[10282.52991683]],acc:0.8533214581861737\n",
            "loss:[[10282.52953334]],acc:0.8533214581861737\n",
            "loss:[[10282.52916972]],acc:0.8533214581861737\n",
            "loss:[[10282.52882452]],acc:0.8533214581861737\n",
            "loss:[[10282.5284964]],acc:0.8533214581861737\n",
            "loss:[[10282.52818415]],acc:0.8533214581861737\n",
            "loss:[[10282.52788663]],acc:0.8533214581861737\n",
            "loss:[[10282.52760282]],acc:0.8533214581861737\n",
            "loss:[[10282.52733175]],acc:0.8533214581861737\n",
            "loss:[[10282.52707256]],acc:0.8533214581861737\n",
            "loss:[[10282.52682443]],acc:0.8533214581861737\n",
            "loss:[[10282.52658661]],acc:0.8533214581861737\n",
            "loss:[[10282.52635843]],acc:0.8533214581861737\n",
            "loss:[[10282.52613925]],acc:0.8533214581861737\n",
            "loss:[[10282.52592849]],acc:0.8533214581861737\n",
            "loss:[[10282.5257256]],acc:0.8533214581861737\n",
            "loss:[[10282.5255301]],acc:0.8533214581861737\n",
            "loss:[[10282.52534152]],acc:0.8533214581861737\n",
            "loss:[[10282.52515944]],acc:0.8533214581861737\n",
            "loss:[[10282.52498346]],acc:0.8533214581861737\n",
            "loss:[[10282.52481324]],acc:0.8533214581861737\n",
            "loss:[[10282.52464842]],acc:0.8533214581861737\n",
            "loss:[[10282.52448871]],acc:0.8533214581861737\n",
            "loss:[[10282.52433381]],acc:0.8533214581861737\n",
            "loss:[[10282.52418346]],acc:0.8533214581861737\n",
            "loss:[[10282.52403741]],acc:0.8533214581861737\n",
            "loss:[[10282.52389543]],acc:0.8533214581861737\n",
            "loss:[[10282.52375731]],acc:0.8533214581861737\n",
            "loss:[[10282.52362285]],acc:0.8533214581861737\n",
            "loss:[[10282.52349186]],acc:0.8533214581861737\n",
            "loss:[[10282.52336419]],acc:0.8533214581861737\n",
            "loss:[[10282.52323966]],acc:0.8533214581861737\n",
            "loss:[[10282.52311812]],acc:0.8533214581861737\n",
            "loss:[[10282.52299945]],acc:0.8533214581861737\n",
            "loss:[[10282.52288351]],acc:0.8533214581861737\n",
            "loss:[[10282.52277017]],acc:0.8533214581861737\n",
            "loss:[[10282.52265933]],acc:0.8533214581861737\n",
            "loss:[[10282.52255088]],acc:0.8533214581861737\n",
            "loss:[[10282.52244473]],acc:0.8533214581861737\n",
            "loss:[[10282.52234077]],acc:0.8533214581861737\n",
            "loss:[[10282.52223892]],acc:0.8533214581861737\n",
            "loss:[[10282.52213911]],acc:0.8533214581861737\n",
            "loss:[[10282.52204124]],acc:0.8533214581861737\n",
            "loss:[[10282.52194526]],acc:0.8533214581861737\n",
            "loss:[[10282.52185109]],acc:0.8533214581861737\n",
            "loss:[[10282.52175866]],acc:0.8533214581861737\n",
            "loss:[[10282.52166793]],acc:0.8533214581861737\n",
            "loss:[[10282.52157882]],acc:0.8533214581861737\n",
            "loss:[[10282.52149129]],acc:0.8533214581861737\n",
            "loss:[[10282.52140528]],acc:0.8533214581861737\n",
            "loss:[[10282.52132075]],acc:0.8533214581861737\n",
            "loss:[[10282.52123764]],acc:0.8533214581861737\n",
            "loss:[[10282.52115593]],acc:0.8533214581861737\n",
            "loss:[[10282.52107555]],acc:0.8533214581861737\n",
            "loss:[[10282.52099649]],acc:0.8533214581861737\n",
            "loss:[[10282.52091869]],acc:0.8533214581861737\n",
            "loss:[[10282.52084212]],acc:0.8533214581861737\n",
            "loss:[[10282.52076674]],acc:0.8533214581861737\n",
            "loss:[[10282.52069254]],acc:0.8533214581861737\n",
            "loss:[[10282.52061946]],acc:0.8533214581861737\n",
            "loss:[[10282.52054749]],acc:0.8533214581861737\n",
            "loss:[[10282.52047659]],acc:0.8533214581861737\n",
            "loss:[[10282.52040674]],acc:0.8533214581861737\n",
            "loss:[[10282.52033792]],acc:0.8533214581861737\n",
            "loss:[[10282.52027008]],acc:0.8533214581861737\n",
            "loss:[[10282.52020323]],acc:0.8533214581861737\n",
            "loss:[[10282.52013731]],acc:0.8533214581861737\n",
            "loss:[[10282.52007233]],acc:0.8533214581861737\n",
            "loss:[[10282.52000825]],acc:0.8533214581861737\n",
            "loss:[[10282.51994506]],acc:0.8533214581861737\n",
            "loss:[[10282.51988272]],acc:0.8533214581861737\n",
            "loss:[[10282.51982124]],acc:0.8533214581861737\n",
            "loss:[[10282.51976058]],acc:0.8533214581861737\n",
            "loss:[[10282.51970073]],acc:0.8533214581861737\n",
            "loss:[[10282.51964167]],acc:0.8533214581861737\n",
            "loss:[[10282.51958339]],acc:0.8533214581861737\n",
            "loss:[[10282.51952586]],acc:0.8533214581861737\n",
            "loss:[[10282.51946908]],acc:0.8533214581861737\n",
            "loss:[[10282.51941302]],acc:0.8533214581861737\n",
            "loss:[[10282.51935768]],acc:0.8533214581861737\n",
            "loss:[[10282.51930304]],acc:0.8533214581861737\n",
            "loss:[[10282.51924908]],acc:0.8533214581861737\n",
            "loss:[[10282.51919579]],acc:0.8533214581861737\n",
            "loss:[[10282.51914316]],acc:0.8533214581861737\n",
            "loss:[[10282.51909117]],acc:0.8533214581861737\n",
            "loss:[[10282.51903982]],acc:0.8533214581861737\n",
            "loss:[[10282.5189891]],acc:0.8533214581861737\n",
            "loss:[[10282.51893898]],acc:0.8533214581861737\n",
            "loss:[[10282.51888945]],acc:0.8533214581861737\n",
            "loss:[[10282.51884052]],acc:0.8533214581861737\n",
            "loss:[[10282.51879217]],acc:0.8533214581861737\n",
            "loss:[[10282.51874438]],acc:0.8533214581861737\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "#must pay attention : instead of mul(w,x) + b, is sum(mul(w,x)) + b\ndim,n \u003d data_x.shape\nw \u003d np.random.normal(0,0.02,(dim,1))\n#w \u003d np.ones((dim,1))\nb \u003d np.zeros((1,1))\nlr \u003d 0.3\nepoches \u003d 2000\n\ndef shuffle(vali_ratio \u003d 0.2):\n    seed \u003d np.random.randint(0,1e6)\n\n    np.random.seed(seed)\n    np.random.shuffle(data_x)\n    np.random.seed(seed)\n    np.random.shuffle(data_y)\n    \n    return data_x,data_y\n\ndef sigmoid(x):\n    return 1./(1.+ np.exp(-x))\n\ndef f(x,w,b):\n    return sigmoid(np.matmul(w.T,x) + b)\n\ndef loss(x,y):\n    pred \u003d f(x,w,b)\n    pred_log \u003d np.log(pred)#q(1) \u003d f(x)\n    no_pred_log \u003d np.log(1.0-pred)#q(0) \u003d 1 - f(x) ; f(x) : probability of class A(1)\n    loss_val \u003d -1.* (np.matmul(y,pred_log.T) + np.matmul((1.0-y),no_pred_log.T))\n    return loss_val\n\ndef accuarcy(x,y):\n    pred \u003df(x,w,b)\n    pred \u003d np.rint(pred)\n    return np.mean(np.equal(pred,y).astype(\u0027float\u0027))\n    \nw_g_square_sum \u003d np.zeros((dim,1))\nb_g_square_sum \u003d np.zeros((1,1))\nfor i in range(epoches):\n    #if this program is interrupted,and this shuffle function is not end,the data wiil wrong\n    #the data_x and data_y may not match again...\n    #x,y \u003d shuffle() \n    \n    x \u003d data_x\n    y \u003d data_y\n   \n    w_g \u003d np.matmul(-x, (y - f(x,w,b)).T)#(1,dim)\n    b_g \u003d np.dot(-np.ones((1,n)),(y - f(x,w,b)).T)#(1,1)\n    \n    w_g_square_sum +\u003d w_g ** 2\n    b_g_square_sum +\u003d b_g ** 2\n    \n    w1 \u003d w - (lr / np.sqrt(w_g_square_sum))*(w_g)\n    b1 \u003d b - (lr / np.sqrt(b_g_square_sum))*(b_g)\n    \n    w \u003d w1\n    b \u003d b1\n    if i % 10 \u003d\u003d 0 :\n        print(\"loss:{},acc:{}\".format(loss(x,y),accuarcy(x,y)))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% disctrimitive model \n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "f \u003d open(\"./result/salary/wb\",\u0027w\u0027)\nf.writelines(str(w).replace(\u0027  \u0027,\u0027,\u0027))\nf.writelines(str(b))\nf.close()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% write w and b\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "C:\\Users\\a2323\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "C:\\Users\\a2323\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  del sys.path[0]\nC:\\Users\\a2323\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "def load_test(df,obj_dict):\n    col_name \u003d df.columns.values\n    obj_list \u003d []\n    for name in col_name:\n        if df[name].dtype \u003d\u003d \u0027object\u0027:\n            obj_list.append(name)\n   \n    for name in obj_list:#list of object column\n        keys \u003d list(obj_dict[name])#various value of this column\n        \n        if len(keys) \u003c\u003d 2 :#value types no more than 2,change previous column only;no prefix\n            df_col \u003d df[name]\n            df_col[df[name] \u003d\u003d keys[0]] \u003d 0\n            df_col[df[name] !\u003d 0] \u003d 1\n        else:#need convert to on-hot,i.e.need add and drop columns\n            keys \u003d [key[len(name)+1:] for key in keys]#has prefix\n            for key in keys:\n                #add new col\n                col_name \u003d name+\"_\"+key\n                df[col_name] \u003d 0\n                new_col \u003d df[col_name]\n                new_col[df[name] \u003d\u003d key] \u003d 1\n                obj_dict[name].append(col_name)\n                \n            #drop col\n            df.drop(name,axis \u003d 1,inplace\u003dTrue)\n        \n    return df\n\ndf_t \u003d pd.read_csv(\"./data/salary/test.csv\",encoding\u003d\u0027Big5\u0027)\ndf_t_c \u003d load_test(df_t,obj_dict)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% def function\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": "df_t_c.to_csv(\"./result/salary/temp.csv\")",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "source": "test_x \u003d df_t_c.values.astype(\u0027float\u0027).T #(dim,n)\n#remember feature scaling\ntest_x \u003d (test_x - np.mean(test_x,axis\u003d1).reshape((-1,1)))/(np.std(test_x,axis\u003d1)+ 1e-10).reshape((-1,1))\n\npred \u003d f(test_x,w,b)\npred \u003d np.rint(pred).reshape((-1,))#\u003c\u003d50K : 0; \u003e50K : 1\n\npred_list \u003d list(pred)\nid_list \u003d range(1,len(pred)+1)\ndf_out \u003d pd.DataFrame({\u0027id\u0027:id_list,\u0027label\u0027:pred_list},dtype\u003d\u0027int\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "source": "df_out.to_csv(\"./result/salary/pred.csv\",index\u003dFalse)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "data": {
            "text/plain": "(16281,)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 18
        }
      ],
      "source": "test_x - np.mean(test_x,axis\u003d0)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}